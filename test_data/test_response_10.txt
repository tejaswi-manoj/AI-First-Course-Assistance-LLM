What features the model has learned (via filter visualizations).
How it responds to specific input (via activation maps highlighting what parts of input trigger certain features).
Structure in the learned representation (via embeddings plots).
For instance, in an image classifier, we might show saliency maps, we might be:
Pooling layers recognition might be an abstracts, we might show saliency maps (edges, orientations, colors) and later ones capture more complex motifs (parts of objects, textures). Visualizing activations