Model checkpoint saved at iteration 100000 to ./models/model_GPT_AdamW_mixdataset_10000_iter100000.pth
step 100096: train loss 0.1268, val loss 0.2945
step 100352: train loss 0.0890, val loss 0.2354
Model checkpoint saved at iteration 100500 to ./models/model_GPT_AdamW_mixdataset_10000_iter100500.pth
step 100608: train loss 0.0722, val loss 0.1975
step 100864: train loss 0.0647, val loss 0.1894
Model checkpoint saved at iteration 101000 to ./models/model_GPT_AdamW_mixdataset_10000_iter101000.pth
step 101120: train loss 0.0627, val loss 0.1750
step 101376: train loss 0.0587, val loss 0.1831
Model checkpoint saved at iteration 101500 to ./models/model_GPT_AdamW_mixdataset_10000_iter101500.pth
step 101632: train loss 0.0554, val loss 0.1839
step 101888: train loss 0.0556, val loss 0.1864
Model checkpoint saved at iteration 102000 to ./models/model_GPT_AdamW_mixdataset_10000_iter102000.pth
step 102144: train loss 0.0513, val loss 0.1942
step 102400: train loss 0.0513, val loss 0.1978
Model checkpoint saved at iteration 102500 to ./models/model_GPT_AdamW_mixdataset_10000_iter102500.pth
step 102656: train loss 0.0510, val loss 0.1978
step 102912: train loss 0.0505, val loss 0.1998
Model checkpoint saved at iteration 103000 to ./models/model_GPT_AdamW_mixdataset_10000_iter103000.pth
step 103168: train loss 0.0502, val loss 0.1981
step 103424: train loss 0.0495, val loss 0.1953
Model checkpoint saved at iteration 103500 to ./models/model_GPT_AdamW_mixdataset_10000_iter103500.pth
step 103680: train loss 0.0495, val loss 0.1996
step 103936: train loss 0.0491, val loss 0.2001
Model checkpoint saved at iteration 104000 to ./models/model_GPT_AdamW_mixdataset_10000_iter104000.pth
step 104192: train loss 0.0501, val loss 0.2025
step 104448: train loss 0.0495, val loss 0.2061
Model checkpoint saved at iteration 104500 to ./models/model_GPT_AdamW_mixdataset_10000_iter104500.pth
step 104704: train loss 0.0491, val loss 0.2025
step 104960: train loss 0.0493, val loss 0.2020
Model checkpoint saved at iteration 105000 to ./models/model_GPT_AdamW_mixdataset_10000_iter105000.pth
step 105216: train loss 0.0491, val loss 0.2098
step 105472: train loss 0.0493, val loss 0.2028
Model checkpoint saved at iteration 105500 to ./models/model_GPT_AdamW_mixdataset_10000_iter105500.pth
step 105728: train loss 0.0486, val loss 0.2064
step 105984: train loss 0.0505, val loss 0.2075
Model checkpoint saved at iteration 106000 to ./models/model_GPT_AdamW_mixdataset_10000_iter106000.pth
step 106240: train loss 0.0482, val loss 0.2047
step 106496: train loss 0.0479, val loss 0.2014
Model checkpoint saved at iteration 106500 to ./models/model_GPT_AdamW_mixdataset_10000_iter106500.pth
step 106752: train loss 0.0485, val loss 0.2099
Model checkpoint saved at iteration 107000 to ./models/model_GPT_AdamW_mixdataset_10000_iter107000.pth
step 107008: train loss 0.0485, val loss 0.2069
step 107264: train loss 0.0486, val loss 0.2107
Model checkpoint saved at iteration 107500 to ./models/model_GPT_AdamW_mixdataset_10000_iter107500.pth
step 107520: train loss 0.0478, val loss 0.2068
step 107776: train loss 0.0488, val loss 0.2160
Model checkpoint saved at iteration 108000 to ./models/model_GPT_AdamW_mixdataset_10000_iter108000.pth
step 108032: train loss 0.0496, val loss 0.2126
step 108288: train loss 0.0480, val loss 0.2073
Model checkpoint saved at iteration 108500 to ./models/model_GPT_AdamW_mixdataset_10000_iter108500.pth
step 108544: train loss 0.0475, val loss 0.2132
step 108800: train loss 0.0477, val loss 0.2091
Model checkpoint saved at iteration 109000 to ./models/model_GPT_AdamW_mixdataset_10000_iter109000.pth
step 109056: train loss 0.0478, val loss 0.2089
step 109312: train loss 0.0474, val loss 0.2104
Model checkpoint saved at iteration 109500 to ./models/model_GPT_AdamW_mixdataset_10000_iter109500.pth
step 109568: train loss 0.0476, val loss 0.2082
step 109824: train loss 0.0478, val loss 0.2085
Final model saved to ./models/model_GPT_AdamW_mixdataset_10000.pth
