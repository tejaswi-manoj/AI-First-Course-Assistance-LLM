step 0: train loss 10.8755, val loss 10.8707
step 256: train loss 10.7907, val loss 10.7943
Model saved at iteration 500 to ./models/model_GPT_AdamW_lr5_iter500.pth
step 512: train loss 10.7140, val loss 10.7261
step 768: train loss 10.6459, val loss 10.6653
Model saved at iteration 1000 to ./models/model_GPT_AdamW_lr5_iter1000.pth
step 1024: train loss 10.5847, val loss 10.6104
step 1280: train loss 10.5274, val loss 10.5586
Model saved at iteration 1500 to ./models/model_GPT_AdamW_lr5_iter1500.pth
step 1536: train loss 10.4723, val loss 10.5088
step 1792: train loss 10.4185, val loss 10.4594
Model saved at iteration 2000 to ./models/model_GPT_AdamW_lr5_iter2000.pth
step 2048: train loss 10.3651, val loss 10.4104
step 2304: train loss 10.3106, val loss 10.3616
Model saved at iteration 2500 to ./models/model_GPT_AdamW_lr5_iter2500.pth
step 2560: train loss 10.2557, val loss 10.3116
step 2816: train loss 10.1992, val loss 10.2595
Model saved at iteration 3000 to ./models/model_GPT_AdamW_lr5_iter3000.pth
step 3072: train loss 10.1408, val loss 10.2062
step 3328: train loss 10.0815, val loss 10.1519
Model saved at iteration 3500 to ./models/model_GPT_AdamW_lr5_iter3500.pth
step 3584: train loss 10.0216, val loss 10.0962
step 3840: train loss 9.9562, val loss 10.0374
Model saved at iteration 4000 to ./models/model_GPT_AdamW_lr5_iter4000.pth
step 4096: train loss 9.8913, val loss 9.9773
step 4352: train loss 9.8241, val loss 9.9148
Model saved at iteration 4500 to ./models/model_GPT_AdamW_lr5_iter4500.pth
step 4608: train loss 9.7555, val loss 9.8515
step 4864: train loss 9.6825, val loss 9.7862
Model saved at iteration 5000 to ./models/model_GPT_AdamW_lr5_iter5000.pth
step 5120: train loss 9.6099, val loss 9.7182
step 5376: train loss 9.5321, val loss 9.6504
Model saved at iteration 5500 to ./models/model_GPT_AdamW_lr5_iter5500.pth
step 5632: train loss 9.4586, val loss 9.5812
step 5888: train loss 9.3845, val loss 9.5152
Model saved at iteration 6000 to ./models/model_GPT_AdamW_lr5_iter6000.pth
step 6144: train loss 9.3141, val loss 9.4485
step 6400: train loss 9.2441, val loss 9.3893
Model saved at iteration 6500 to ./models/model_GPT_AdamW_lr5_iter6500.pth
step 6656: train loss 9.1847, val loss 9.3355
step 6912: train loss 9.1346, val loss 9.2964
Model saved at iteration 7000 to ./models/model_GPT_AdamW_lr5_iter7000.pth
step 7168: train loss 9.1007, val loss 9.2639
step 7424: train loss 9.0737, val loss 9.2444
Model saved at iteration 7500 to ./models/model_GPT_AdamW_lr5_iter7500.pth
step 7680: train loss 9.0474, val loss 9.2217
step 7936: train loss 9.0113, val loss 9.1884
Model saved at iteration 8000 to ./models/model_GPT_AdamW_lr5_iter8000.pth
step 8192: train loss 8.9546, val loss 9.1315
step 8448: train loss 8.8823, val loss 9.0569
Model saved at iteration 8500 to ./models/model_GPT_AdamW_lr5_iter8500.pth
step 8704: train loss 8.7913, val loss 8.9663
step 8960: train loss 8.6993, val loss 8.8679
Model saved at iteration 9000 to ./models/model_GPT_AdamW_lr5_iter9000.pth
step 9216: train loss 8.6087, val loss 8.7736
step 9472: train loss 8.5249, val loss 8.6888
Model saved at iteration 9500 to ./models/model_GPT_AdamW_lr5_iter9500.pth
step 9728: train loss 8.4492, val loss 8.6114
step 9984: train loss 8.3849, val loss 8.5435
