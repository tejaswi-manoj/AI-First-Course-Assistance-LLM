Batch size used here was 64 

Model checkpoint saved at iteration 70000 to ./models/model_GPT_AdamW_generated_80000_latest_iter70000.pth
step 70144: train loss 0.0398, val loss 0.0430
step 70400: train loss 0.0391, val loss 0.0428
Model checkpoint saved at iteration 70500 to ./models/model_GPT_AdamW_generated_80000_latest_iter70500.pth
step 70656: train loss 0.0395, val loss 0.0426
step 70912: train loss 0.0396, val loss 0.0421
Model checkpoint saved at iteration 71000 to ./models/model_GPT_AdamW_generated_80000_latest_iter71000.pth
step 71168: train loss 0.0396, val loss 0.0424
step 71424: train loss 0.0397, val loss 0.0428
Model checkpoint saved at iteration 71500 to ./models/model_GPT_AdamW_generated_80000_latest_iter71500.pth
step 71680: train loss 0.0412, val loss 0.0437
step 71936: train loss 0.0403, val loss 0.0434
Model checkpoint saved at iteration 72000 to ./models/model_GPT_AdamW_generated_80000_latest_iter72000.pth
step 72192: train loss 0.0395, val loss 0.0429
step 72448: train loss 0.0401, val loss 0.0440
Model checkpoint saved at iteration 72500 to ./models/model_GPT_AdamW_generated_80000_latest_iter72500.pth
step 72704: train loss 0.0404, val loss 0.0437
step 72960: train loss 0.0400, val loss 0.0427
Model checkpoint saved at iteration 73000 to ./models/model_GPT_AdamW_generated_80000_latest_iter73000.pth
step 73216: train loss 0.0396, val loss 0.0429
step 73472: train loss 0.0398, val loss 0.0432
Model checkpoint saved at iteration 73500 to ./models/model_GPT_AdamW_generated_80000_latest_iter73500.pth
step 73728: train loss 0.0393, val loss 0.0430
step 73984: train loss 0.0397, val loss 0.0428
Model checkpoint saved at iteration 74000 to ./models/model_GPT_AdamW_generated_80000_latest_iter74000.pth
step 74240: train loss 0.0394, val loss 0.0428
step 74496: train loss 0.0395, val loss 0.0431
Model checkpoint saved at iteration 74500 to ./models/model_GPT_AdamW_generated_80000_latest_iter74500.pth
step 74752: train loss 0.0400, val loss 0.0430
Model checkpoint saved at iteration 75000 to ./models/model_GPT_AdamW_generated_80000_latest_iter75000.pth
step 75008: train loss 0.0397, val loss 0.0428
step 75264: train loss 0.0398, val loss 0.0422
Model checkpoint saved at iteration 75500 to ./models/model_GPT_AdamW_generated_80000_latest_iter75500.pth
step 75520: train loss 0.0395, val loss 0.0417
step 75776: train loss 0.0396, val loss 0.0429
Model checkpoint saved at iteration 76000 to ./models/model_GPT_AdamW_generated_80000_latest_iter76000.pth
step 76032: train loss 0.0398, val loss 0.0427
step 76288: train loss 0.0392, val loss 0.0427
Model checkpoint saved at iteration 76500 to ./models/model_GPT_AdamW_generated_80000_latest_iter76500.pth
step 76544: train loss 0.0397, val loss 0.0432
step 76800: train loss 0.0394, val loss 0.0431
Model checkpoint saved at iteration 77000 to ./models/model_GPT_AdamW_generated_80000_latest_iter77000.pth
step 77056: train loss 0.0392, val loss 0.0428
step 77312: train loss 0.0393, val loss 0.0427
Model checkpoint saved at iteration 77500 to ./models/model_GPT_AdamW_generated_80000_latest_iter77500.pth
step 77568: train loss 0.0391, val loss 0.0434
step 77824: train loss 0.0392, val loss 0.0429
Model checkpoint saved at iteration 78000 to ./models/model_GPT_AdamW_generated_80000_latest_iter78000.pth
step 78080: train loss 0.0402, val loss 0.0423
step 78336: train loss 0.0398, val loss 0.0426
Model checkpoint saved at iteration 78500 to ./models/model_GPT_AdamW_generated_80000_latest_iter78500.pth
step 78592: train loss 0.0395, val loss 0.0426
step 78848: train loss 0.0392, val loss 0.0426
Model checkpoint saved at iteration 79000 to ./models/model_GPT_AdamW_generated_80000_latest_iter79000.pth
step 79104: train loss 0.0387, val loss 0.0424
step 79360: train loss 0.0390, val loss 0.0425
Model checkpoint saved at iteration 79500 to ./models/model_GPT_AdamW_generated_80000_latest_iter79500.pth
step 79616: train loss 0.0390, val loss 0.0419
step 79872: train loss 0.0392, val loss 0.0422
Final model saved to ./models/model_GPT_AdamW_generated_80000_latest.pth
